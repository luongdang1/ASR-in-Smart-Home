# ASR-in-Smart-Home
SmartHome-ASR is a speech recognition system built on the DeepSpeech2 architecture (originally from Mozilla), trained from scratch with the Fluent Speech Commands Dataset to support smart home applications.

ğŸ“Œ Highlights
ğŸ”§ Production-ready: Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ triá»ƒn khai dá»… dÃ ng trong mÃ´i trÆ°á»ng thá»±c táº¿.

ğŸ§  Bi-GRU Architecture: Khai thÃ¡c kiáº¿n trÃºc RNN hai chiá»u Ä‘á»ƒ náº¯m báº¯t ngá»¯ cáº£nh toÃ n cá»¥c.

ğŸ”¤ CTC Loss: Huáº¥n luyá»‡n khÃ´ng cáº§n cÄƒn chá»‰nh chÃ­nh xÃ¡c tá»«ng khung Ã¢m thanh vá»›i kÃ½ tá»±.

ğŸ“ˆ Tá»‘i Æ°u hÃ³a cho nhÃ  thÃ´ng minh: Nháº­n dáº¡ng cÃ¡c lá»‡nh Ä‘iá»u khiá»ƒn nhÆ° "turn on the lights", "set temperature", v.v.

ğŸ“‚ Dataset
Fluent Speech Commands Dataset

NgÃ´n ngá»¯: Tiáº¿ng Anh

Dáº¡ng dá»¯ liá»‡u: Táº­p .wav vá»›i nhÃ£n dáº¡ng cÃ¢u lá»‡nh

VÃ­ dá»¥: "turn on the lights in the kitchen"

Táº­p huáº¥n luyá»‡n cÃ³ sáºµn cho nhiá»u speaker â†’ Ä‘a dáº¡ng giá»ng nÃ³i

âš™ï¸ MÃ´ hÃ¬nh
ğŸ” Kiáº¿n trÃºc tá»•ng thá»ƒ
Feature extraction: STFT â†’ Spectrogram

Encoder: Nhiá»u táº§ng Bi-GRU

CTC Loss: Tá»‘i Æ°u hÃ³a há»c chuá»—i khÃ´ng cÄƒn chá»‰nh

<p align="center"> <img src="Picture_1751183842" alt="Bi-GRU Architecture" width="600"/> </p>
âœ¨ CTC Loss â€“ Connectionist Temporal Classification
Cho phÃ©p huáº¥n luyá»‡n khÃ´ng cáº§n gÃ¡n nhÃ£n tá»«ng frame Ã¢m thanh vá»›i kÃ½ tá»± cá»¥ thá»ƒ.

QuÃ¡ trÃ¬nh suy luáº­n:

Dá»± Ä‘oÃ¡n chuá»—i kÃ½ tá»± cÃ³ cáº£ blank vÃ  láº·p láº¡i.

Merge duplicates: loáº¡i bá» kÃ½ tá»± láº·p liÃªn tiáº¿p.

Remove blanks: loáº¡i bá» kÃ½ hiá»‡u blank Ä‘á»ƒ táº¡o ra chuá»—i cuá»‘i cÃ¹ng.

<p align="center"> <img src="Picture_1167238156" alt="CTC Explanation" width="600"/> </p>
ğŸ“ˆ Káº¿t quáº£ cÄƒn chá»‰nh (Alignment Example)
Há»‡ thá»‘ng cÃ³ thá»ƒ cÄƒn chá»‰nh tá»« vá»›i vÃ¹ng Ã¢m thanh tÆ°Æ¡ng á»©ng.

HÃ¬nh minh há»a vÃ¹ng phÃ¡t Ã¢m tÆ°Æ¡ng á»©ng cho tá»«ng tá»« (highlight ná»n mÃ u).

<p align="center"> <img src="Picture_226716643" alt="Waveform Alignment" width="600"/> </p>
ğŸš€ CÃ i Ä‘áº·t
YÃªu cáº§u:
Python â‰¥ 3.10

Conda (Ä‘á» xuáº¥t dÃ¹ng Miniconda)

CUDA 12.1

PyTorch â‰¥ 2.2.2 + cu121

Libsox (Ã¢m thanh)

CÃ¡c bÆ°á»›c:
bash
Sao chÃ©p
Chá»‰nh sá»­a
# Clone dá»± Ã¡n
git clone https://github.com/your-username/SmartHome-ASR.git
cd SmartHome-ASR

# Táº¡o mÃ´i trÆ°á»ng Conda
conda create -n smarthome-asr python=3.10
conda activate smarthome-asr

# CÃ i Ä‘áº·t phá»¥ thuá»™c
pip install -r requirements.txt

# CÃ i Ä‘áº·t CUDA, Torch (náº¿u dÃ¹ng GPU)
pip install torch==2.2.2+cu121 torchaudio==2.2.2+cu121 -f https://download.pytorch.org/whl/torch_stable.html

# CÃ i Ä‘áº·t sox náº¿u gáº·p lá»—i liÃªn quan
conda install conda-forge::sox
ğŸ§ª Huáº¥n luyá»‡n & Inference
python
Sao chÃ©p
Chá»‰nh sá»­a
from deepspeech_model import DeepSpeech2Model

model = DeepSpeech2Model.load_pretrained('models/deepspeech2_fsc.pth')
result = model.transcribe('audio/turn_on_light.wav')
print(result['text'])  # Output: turn on the light
ğŸ—‚ Cáº¥u trÃºc thÆ° má»¥c
bash
Sao chÃ©p
Chá»‰nh sá»­a
SmartHome-ASR/
â”œâ”€â”€ data/                   # Dá»¯ liá»‡u Ä‘áº§u vÃ o (.wav, labels)
â”œâ”€â”€ models/                 # Trá»ng sá»‘ mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
â”œâ”€â”€ notebooks/              # PhÃ¢n tÃ­ch dá»¯ liá»‡u & inference
â”œâ”€â”€ scripts/                # Script huáº¥n luyá»‡n, test
â”œâ”€â”€ deepspeech_model.py     # Cáº¥u trÃºc DeepSpeech2
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ“š TÃ i liá»‡u tham kháº£o
Mozilla DeepSpeech

Fluent Speech Commands Dataset

CTC Loss paper

ğŸ“Œ Giáº¥y phÃ©p
Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i MIT License.
